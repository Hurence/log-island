#########################################################################################################
# Logisland configuration script template
#########################################################################################################

version: 1.1.2
documentation: LogIsland analytics main config file. Put here every engine or component config

#########################################################################################################
# engine
engine:
  component: com.hurence.logisland.engine.spark.KafkaStreamProcessingEngine
  type: engine
  documentation: Hurence Analytics - Create consolidate sessions object
  configuration:
    spark.app.name: feed-ES
    spark.master: local[*]
    # spark.deploy-mode: { { .Values.spark.deploy.mode } }
    spark.executor.cores: 1
    # spark.total.executor.cores: { { .Values.spark.totalExecutorCores } }
    spark.driver.memory: 1g
    spark.executor.memory: 1g
    spark.serializer: org.apache.spark.serializer.KryoSerializer
    spark.streaming.backpressure.enabled: true
    spark.streaming.unpersist: false
    spark.streaming.blockInterval: 500
    spark.streaming.timeout: -1
    spark.streaming.kafka.maxRetries: 3
    spark.streaming.ui.retainedBatches: 200
    spark.streaming.receiver.writeAheadLog.enable: false
    spark.ui.port: 4055
    spark.streaming.kafka.maxRatePerPartition: 3000
    spark.streaming.batchDuration: 5000

  controllerServiceConfigurations:

    - controllerService: elasticsearch_service
      component: com.hurence.logisland.service.elasticsearch.Elasticsearch_7_x_ClientService
      type: service
      documentation: elasticsearch service implementation
      configuration:
        hosts: opendistro-es-client-service.hdp-storage:9200
        username: admin
        password: admin
        batch.size: 2000
        flush.interval: 2

  streamConfigurations:

    # parsing
    - stream: parsing_stream
      component: com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing
      type: stream
      documentation: a processor that links
      configuration:
        kafka.input.topics: divolte.events.hurence
        kafka.output.topics: logisland.events.hurence
        kafka.error.topics: logisland.errors.hurence
        kafka.input.topics.serializer: com.hurence.logisland.serializer.ConfluentSerializer
        kafka.output.topics.serializer: com.hurence.logisland.serializer.KryoSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        avro.schema.url: "http://avro-schema-registry.hdp-storage:5000"
        avro.schema.name: "divolte.events.hurence"
        avro.schema.version: 1
        kafka.metadata.broker.list: "hdp-kafka-brokers.hdp-storage:9092"
        kafka.zookeeper.quorum: "hdp-zookeeper-nodes.hdp-storage:2181"
        kafka.topic.autoCreate: false
        kafka.topic.default.partitions: 1
        kafka.topic.default.replicationFactor: 1
#        kafka.manual.offset.reset: smallest

      processorConfigurations:
        - processor: clean_location
          component: com.hurence.logisland.processor.RemoveFields
          type: processor
          documentation: Clean the location
          configuration:
            fields.to.remove: location

        - processor: Websession_index_name
          component: com.hurence.logisland.processor.AddFields
          type: processor
          documentation: a processor that specifies the name of the websession elasticsearch index into a field used by the BulkAdd processor afterward.
          configuration:
            websessionIndex: ${'openanalytics_websessions.' + new java.text.SimpleDateFormat('yyyy.MM').format(new java.util.Date(timestamp));}

        # put to elasticsearch
        - processor: es_publisher
          component: com.hurence.logisland.processor.elasticsearch.BulkAddElasticsearch
          type: processor
          documentation: a processor that stores the web sessions
          configuration:
            elasticsearch.client.service: elasticsearch_service
            es.index.field: websessionIndex
            default.type: sessions
